<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.127.0"><title>How to Upload (Pre)-Annotations to Roboflow | Jordi Smit</title>
<meta name=description content="Learn how to upload annotations and predictions to Roboflow using the Python SDK, allowing you to import pre-existing datasets or create active learning loops programmatically."><meta name=keywords content="computer vision,labeling,roboflow"><link rel=canonical href=https://jordismit.com/blog/how-to-upload-pre-annotations-to-roboflow/><meta property="og:type" content="website"><meta property="og:title" content="How to Upload (Pre)-Annotations to Roboflow | Jordi Smit"><meta property="og:description" content="Learn how to upload annotations and predictions to Roboflow using the Python SDK, allowing you to import pre-existing datasets or create active learning loops programmatically."><meta property="og:site_name" content="Jordi Smit"><meta property="og:url" content="https://jordismit.com/blog/how-to-upload-pre-annotations-to-roboflow/"><meta property="og:locale" content="en"><meta property="og:image" content="https://jordismit.com/blog/how-to-upload-pre-annotations-to-roboflow/images/cover.png"><meta property="og:image:secure_url" content="https://jordismit.com/blog/how-to-upload-pre-annotations-to-roboflow/images/cover.png"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="How to Upload (Pre)-Annotations to Roboflow"><meta name=twitter:description content="Learn how to upload annotations and predictions to Roboflow using the Python SDK, allowing you to import pre-existing datasets or create active learning loops programmatically."><meta name=twitter:site content="@j0rd1smit"><link rel=stylesheet href=https://jordismit.com/css/bootstrap.min.7633b7c0c97d19e682feee8afa2738523fcb2a14544a550572caeecd2eefe66b.css integrity="sha256-djO3wMl9GeaC/u6K+ic4Uj/LKhRUSlUFcsruzS7v5ms="><link rel=stylesheet href=https://jordismit.com/css/goolge-fonts.min.59f98c25da594b2a690835ae556add4bd6b87b555c2be822e4f8d7ed2ac28c55.css integrity="sha256-WfmMJdpZSyppCDWuVWrdS9a4e1VcK+gi5PjX7SrCjFU="><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.0.13/css/all.css integrity=sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp crossorigin=anonymous><link rel=stylesheet href=https://jordismit.com/css/medium.min.edbfa243cc780784f7bc1e894ffbbe0f61381ecc59ea59a8e9736b0adbf727c0.css integrity="sha256-7b+iQ8x4B4T3vB6JT/u+D2E4HsxZ6lmo6XNrCtv3J8A="><link rel=stylesheet href=https://jordismit.com/css/additional.min.df77e97a7aaac1ae6e2eb40724704e1fe7702fe8e085c5bc4b21c2b013c90307.css integrity="sha256-33fpenqqwa5uLrQHJHBOH+dwL+jghcW8SyHCsBPJAwc="><link rel=icon type=image/x-icon href=https://jordismit.com/favicon/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=https://jordismit.com/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://jordismit.com/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://jordismit.com/favicon/favicon-16x16.png><meta name=theme-color content="#fff"><script async src="https://www.googletagmanager.com/gtag/js?id=G-YZP2SLQQK7"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-YZP2SLQQK7")}</script></head><body class="d-flex flex-column min-vh-100"><nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down"><div class="container pr-0"><a class=navbar-brand href=https://jordismit.com//><span style=font-family:Righteous>Jordi Smit</span>
</a><button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarMediumish aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarMediumish><ul class="navbar-nav ms-auto"><li class=nav-item><a class=nav-link href=/blog>Blog</a></li><li class=nav-item><a class=nav-link href=/til>TIL</a></li><li class=nav-item><a class=nav-link href=/cheat-sheets>Cheat-sheets</a></li><li class=nav-item><a class=nav-link href=/about>About Me</a></li></ul></div></div></nav><div class=site-content><div class=container><div class=main-content><div class=container><div class=row><div class="col-md-2 pl-0"><div class="share sticky-top sticky-top-offset"><p>Share</p><ul><li class="ml-1 mr-1"><a target=_blank href="https://twitter.com/intent/tweet?text=How%20to%20Upload%20%28Pre%29-Annotations%20to%20Roboflow&url=https%3a%2f%2fjordismit.com%2fblog%2fhow-to-upload-pre-annotations-to-roboflow%2f" onclick='return window.open(this.href,"twitter-share","width=550,height=435"),!1'><i class="fab fa-twitter"></i></a></li><li class="ml-1 mr-1"><a target=_blank href="https://facebook.com/sharer.php?u=https%3a%2f%2fjordismit.com%2fblog%2fhow-to-upload-pre-annotations-to-roboflow%2f" onclick='return window.open(this.href,"facebook-share","width=550,height=435"),!1'><i class="fab fa-facebook-f"></i></a></li><li class="ml-1 mr-1"><a target=_blank href="https://www.linkedin.com/sharing/share-offsite/?url=https%3a%2f%2fjordismit.com%2fblog%2fhow-to-upload-pre-annotations-to-roboflow%2f" onclick='return window.open(this.href,"linkedin-share","width=550,height=435"),!1'><i class="fab fa-linkedin"></i></a></li></ul></div></div><div class="col-md-9 flex-first flex-md-unordered"><div class=mainheading><div class="row post-top-meta"><div class="col-xs-12 col-md-3 col-lg-2 text-center text-md-left mb-4 mb-md-0 md-nopad-right"><a href=/about><img class=author-thumb src=https://jordismit.com/media/images/author_hu25d333fcded103db2f52f7476cb1420a_204682_250x0_resize_q75_box.jpg alt=Author></a></div><div class="col-xs-12 col-md-9 col-lg-10 text-center text-md-start md-nopad-left"><a href=/about class=link-dark>Jordi
Smit</a><br><span class=author-description>Machine Learning Engineer<br>13 Jun 2024
<i class="far fa-clock clock"></i>
5 min read</span></div></div><h1 class=posttitle>How to Upload (Pre)-Annotations to Roboflow</h1></div><div class=post-featured-image><img class=img-fluid src=https://jordismit.com/blog/how-to-upload-pre-annotations-to-roboflow/images/cover.png alt="thumbnail for this post"></div><div class=article-post><p>I&rsquo;m a big fan of Roboflow.
They have one of the most user-friendly labeling interfaces.
I have been using it for quite some time now.
However, only recently did I learn that you can also upload annotations and predictions programmatically.
This creates some new possibilities like:</p><ul><li>Programmatically importing pre-existing datasets.</li><li>Uploading pre-annotations to speed up the labeling process.</li><li>Creating active learning loops.</li><li>And much more.</li></ul><p>Sadly, the documentation is not entirely clear on how to use this feature.
So, in this post, I will show you how to use the Roboflow Python SDK to upload annotations and predictions to your Roboflow projects.</p><h2 id=preparing-the-environment>Preparing the Environment</h2><p>Before we can start, we have to gather some information first.
You will need your Roboflow API key, the name of your workspace, and the name of your project.
The workspace and project name can be found in the project URL: <code>https://app.roboflow.com/workspaces/&lt;your-workspace>/projects/&lt;your-project></code>.
You can find your API key at: <code>https://app.roboflow.com/&lt;your-workspace>/settings/api</code>.
Let&rsquo;s store these values in a <code>.env</code> file or in environment variables using the following names:</p><ul><li><code>ROBOFLOW_API_KEY</code></li><li><code>ROBOFLOW_WORKSPACE</code></li><li><code>ROBOFLOW_PROJECT</code></li></ul><p>The final step we need to take is to install the <a href=https://docs.roboflow.com/api-reference/install-python-package>Roboflow SDK</a>.
You can do this using pip.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>pip install roboflow
</span></span></code></pre></div><p>After that is done, we should be ready to get started.</p><h2 id=upload-annotations-and-predictions>Upload Annotations and Predictions</h2><p>We will use the <a href=https://docs.roboflow.com/api-reference/images/upload-an-annotation>single_upload</a> API endpoint to upload our annotations and predictions.
To use this function, we need three files:</p><ul><li>The image file. Make sure this image has no orientation metadata, read here more why in my blog post: <a href=/blog/how-to-avoid-orientation-bugs-in-computer-vision-labeling/>How to avoid orientation bugs in Computer Vision labeling?</a>.</li><li>The annotation file. This file should be in the YOLO text format for either bounding boxes (<code>class_idx x_center y_center width height</code>) or polygons (<code>class_idx x_1 y_1 ... x_n y_n</code>), with normalized coordinates between 0 and 1.</li><li>The label mapping file. The i-th line in this file contains the name of the corresponding class.</li></ul><p>After you have prepared all these files, you can upload them to Roboflow using the following code.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> roboflow <span style=color:#f92672>import</span> Roboflow
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> os
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>rf <span style=color:#f92672>=</span> Roboflow(api_key<span style=color:#f92672>=</span>os<span style=color:#f92672>.</span>environ[<span style=color:#e6db74>&#34;ROBOFLOW_API_KEY&#34;</span>])
</span></span><span style=display:flex><span>rf_workspace <span style=color:#f92672>=</span> rf<span style=color:#f92672>.</span>workspace(os<span style=color:#f92672>.</span>environ[<span style=color:#e6db74>&#34;ROBOFLOW_WORKSPACE&#34;</span>])
</span></span><span style=display:flex><span>rf_project <span style=color:#f92672>=</span> rf_workspace<span style=color:#f92672>.</span>project(os<span style=color:#f92672>.</span>environ[<span style=color:#e6db74>&#34;ROBOFLOW_PROJECT&#34;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>image_path <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;path/to/your/image.jpg&#34;</span>
</span></span><span style=display:flex><span>label_path <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;path/to/your/label.txt&#34;</span>
</span></span><span style=display:flex><span>label_map_path <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;path/to/your/label_mapping.txt&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>response <span style=color:#f92672>=</span> rf_project<span style=color:#f92672>.</span>single_upload(
</span></span><span style=display:flex><span>    image_path<span style=color:#f92672>=</span>str(image_path),
</span></span><span style=display:flex><span>    annotation_path<span style=color:#f92672>=</span>label_path,
</span></span><span style=display:flex><span>    annotation_labelmap<span style=color:#f92672>=</span>str(label_map_path),
</span></span><span style=display:flex><span>    batch_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;my_batch&#34;</span>, 
</span></span><span style=display:flex><span>    is_prediction<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>This code snippet can be used to upload both annotations and predictions.
The only difference is the <code>is_prediction</code> parameter.
If it is set to <code>False</code>, Roboflow directly adds the annotations to your dataset.
If this parameter is set to <code>True</code>, Roboflow will create a new annotation job with the name specified in the <code>batch_name</code> parameter.
That way, the labelers still need to review the annotations and optionally adjust them before they are added to the dataset.
If you use this function to upload multiple images with their predictions using the same <code>batch_name</code>, Roboflow will group them together in a single annotation job.
This way, you have full control over which images and their pre-annotations end up in which annotation job.</p><h2 id=how-does-it-look-like-in-the-ui>How does it look like in the UI?</h2><p>If you specified <code>is_prediction=False</code>, the annotation will be present in your dataset like any other human-made annotation.
If you specified <code>is_prediction=True</code>, you must look for the annotation job before you can see the pre-annotations in the UI.
You can find it by clicking on &lsquo;Annotate&rsquo; in the left menu, which will show you a new unassigned annotation job with the name you specified in the <code>batch_name</code> parameter.</p><figure><img src=/blog/how-to-upload-pre-annotations-to-roboflow/images/new-job-is-waiting.jpg alt="An example of a new unassigned annotation job."><figcaption><p>An example of a new unassigned annotation job.</p></figcaption></figure><p>After you start the labeling job and open the image, you will see the pre-annotations.
These annotations don&rsquo;t have a different label, color, or confidence score.
They look just like any other annotation.
They are still fully editable, so if any of them are wrong, you can click on them and adjust them.</p><figure><img src=/blog/how-to-upload-pre-annotations-to-roboflow/images/pre-annotation-in-labeling-ui.jpg alt="An example of pre-annotations generated by a model. As you can imagine, adjusting these labels is much easier than drawing them from scratch."><figcaption><p>An example of pre-annotations generated by a model. As you can imagine, adjusting these labels is much easier than drawing them from scratch.</p></figcaption></figure><p>Once you are happy, go back to the annotation overview of the labeling job and click on the &lsquo;Add to dataset&rsquo; button.
Afterward, the pre-annotations will be added to your dataset like any other annotation.</p><h2 id=optional-down-sampling-of-polygons>Optional: Down-Sampling of Polygons</h2><p>When you generate pre-annotations for polygons using a model, you might have too many points in the polygon.
When you upload these polygons, it is impossible to adjust them due to the sheer number of points you have to move.
To prevent this, you can downsample your polygons before uploading them.</p><figure><img src=/blog/how-to-upload-pre-annotations-to-roboflow/images/effect_of_downsampling_on_polygon_prediction.jpg alt="The left polygon is the original predicted polygon, and the right polygon is the down-sampled version. The right polygon is much easier to adjust."><figcaption><p>The left polygon is the original predicted polygon, and the right polygon is the down-sampled version. The right polygon is much easier to adjust.</p></figcaption></figure><p>You can down-sample your polygons by removing points that are not essential.
This can be done using the <a href=https://en.wikipedia.org/wiki/Ramer%E2%80%93Douglas%E2%80%93Peucker_algorithm>Douglas Peucker</a> algorithm.
This algorithm finds a polygon that follows a similar path as the original polygon but with fewer points.
You can use the following code to down-sample your polygons.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> math
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>douglas_peucker</span>(
</span></span><span style=display:flex><span>        points: list[tuple[float, float]],
</span></span><span style=display:flex><span>        epsilon: float,
</span></span><span style=display:flex><span>) <span style=color:#f92672>-&gt;</span> list[tuple[float, float]]:
</span></span><span style=display:flex><span>    <span style=color:#75715e># Find the point with the maximum distance</span>
</span></span><span style=display:flex><span>    dmax <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.0</span>
</span></span><span style=display:flex><span>    index <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>1</span>, len(points) <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>):
</span></span><span style=display:flex><span>        d <span style=color:#f92672>=</span> _distance_from_line(points[i], points[<span style=color:#ae81ff>0</span>], points[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>])
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> d <span style=color:#f92672>&gt;</span> dmax:
</span></span><span style=display:flex><span>            index <span style=color:#f92672>=</span> i
</span></span><span style=display:flex><span>            dmax <span style=color:#f92672>=</span> d
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># If max distance is greater than epsilon, recursively simplify</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> dmax <span style=color:#f92672>&gt;=</span> epsilon:
</span></span><span style=display:flex><span>        <span style=color:#75715e># Recursive call</span>
</span></span><span style=display:flex><span>        rec_results1 <span style=color:#f92672>=</span> douglas_peucker(points[:index <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>], epsilon)
</span></span><span style=display:flex><span>        rec_results2 <span style=color:#f92672>=</span> douglas_peucker(points[index:], epsilon)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Build the result list</span>
</span></span><span style=display:flex><span>        result <span style=color:#f92672>=</span> rec_results1[:<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>] <span style=color:#f92672>+</span> rec_results2
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        result <span style=color:#f92672>=</span> [points[<span style=color:#ae81ff>0</span>], points[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> result
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_distance_from_line</span>(
</span></span><span style=display:flex><span>        point: tuple[float, float],
</span></span><span style=display:flex><span>        line_start: tuple[float, float],
</span></span><span style=display:flex><span>        line_end: tuple[float, float]
</span></span><span style=display:flex><span>) <span style=color:#f92672>-&gt;</span> float:
</span></span><span style=display:flex><span>    <span style=color:#75715e># Calculate the distance of point from the line segment (line_start, line_end)</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> line_start <span style=color:#f92672>==</span> line_end:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> math<span style=color:#f92672>.</span>dist(point, line_start)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        num <span style=color:#f92672>=</span> abs((line_end[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>-</span> line_start[<span style=color:#ae81ff>1</span>]) <span style=color:#f92672>*</span> point[<span style=color:#ae81ff>0</span>] <span style=color:#f92672>-</span> (line_end[<span style=color:#ae81ff>0</span>] <span style=color:#f92672>-</span> line_start[<span style=color:#ae81ff>0</span>]) <span style=color:#f92672>*</span> point[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>+</span> line_end[<span style=color:#ae81ff>0</span>] <span style=color:#f92672>*</span>
</span></span><span style=display:flex><span>                  line_start[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>-</span> line_end[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>*</span> line_start[<span style=color:#ae81ff>0</span>])
</span></span><span style=display:flex><span>        den <span style=color:#f92672>=</span> math<span style=color:#f92672>.</span>sqrt((line_end[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>-</span> line_start[<span style=color:#ae81ff>1</span>]) <span style=color:#f92672>**</span> <span style=color:#ae81ff>2</span> <span style=color:#f92672>+</span> (line_end[<span style=color:#ae81ff>0</span>] <span style=color:#f92672>-</span> line_start[<span style=color:#ae81ff>0</span>]) <span style=color:#f92672>**</span> <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> num <span style=color:#f92672>/</span> den
</span></span></code></pre></div><p>In this algorithm, you can control how much you want to down-sample your polygons by tuning the <code>epsilon</code> parameter.
However, this is a trade-off since more down-sampling means less accurate polygons.
So, use this parameter to find the right balance for your use case.</p><h2 id=wrap-up>Wrap Up</h2><p>To wrap up, using the Roboflow Python SDK to upload annotations and predictions opens up many new possibilities.
It has certainly changed how I work with Roboflow.
I hope this insight will help you in your future computer vision adventures.</p></div><div class=after-post-tags><ul class=tags><li><a href=/tags/computer-vision>computer vision</a></li><li><a href=/tags/labeling>labeling</a></li><li><a href=/tags/roboflow>roboflow</a></li></ul></div><div class="row PageNavigation d-flex justify-content-between font-weight-bold"><a class="d-block col-md-6 text-lg-right" href=https://jordismit.com/blog/how-to-avoid-orientation-bugs-in-computer-vision-labeling/>How to avoid orientation bugs in Computer Vision labeling? &#187;</a><div class=clearfix></div></div></div></div></div></div></div></div><footer class="footer mt-auto"><div class=container><div class=row><div class="col-md-12 col-sm-612 text-center">&copy; Copyright
Jordi Smit - All rights reserved</div></div></div></footer><script async src=https://jordismit.com/js/mediumish.min.3d1f9ef9974c0d54cb8ee42c21d007c35b4c9dba6f291fab0d8c2124e022ba2a.js integrity="sha256-PR+e+ZdMDVTLjuQsIdAHw1tMnbpvKR+rDYwhJOAiuio="></script></body></html>